{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5046753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, csv, time, json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509b896",
   "metadata": {},
   "source": [
    "# Парсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73098cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собрано 200 статей\n",
      "Собрано 400 статей\n",
      "Собрано 400 статей\n",
      "Собрано 500 статей\n",
      "Собрано 500 статей\n",
      "Выгрузка завершена. Всего статей: 500\n",
      "Выгрузка завершена. Всего статей: 500\n"
     ]
    }
   ],
   "source": [
    "# openalex\n",
    "URL = 'https://api.openalex.org/works'\n",
    "\n",
    "PARAMS = {\n",
    "    'filter': 'concepts.id:https://openalex.org/C41008148,from_publication_date:1980-01-01',\n",
    "    'per_page': 200,\n",
    "    'cursor': '*'\n",
    "}\n",
    "\n",
    "FIELDS = [\n",
    "    'Year_of_Publication',\n",
    "    'Title_Length_in_Characters',\n",
    "    'Title_Word_Count',\n",
    "    'Number_of_Authors',\n",
    "    'Number_of_Institutions_of_First_Author',\n",
    "    'Number_of_Citations',\n",
    "    'Number_of_References',\n",
    "    'Type_of_Publication',\n",
    "    'Language_of_Publication',\n",
    "    'Primary_Concept_of_Publication',\n",
    "    'Is_Open_Access',\n",
    "    'Open_Access_Type',\n",
    "    'Abstract_Word_Count',\n",
    "    'Concepts_Count',\n",
    "    'Related_Works_Count',\n",
    "    'Locations_Count',\n",
    "    'OA_Locations_Count',\n",
    "    'Has_DOI',\n",
    "    'Institutions_All_Authors_Count',\n",
    "    'Citations_Per_Year',\n",
    "]\n",
    "\n",
    "with open('data.tsv', 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(FIELDS)\n",
    "    total_rows = 0\n",
    "    limit_reached = False\n",
    "    current_year = time.gmtime().tm_year\n",
    "\n",
    "    while total_rows < 500 and not limit_reached:\n",
    "        r = requests.get(URL, params=PARAMS, timeout=60)\n",
    "        data = r.json()\n",
    "\n",
    "        for w in data['results']:\n",
    "            authorships = w.get('authorships') or []\n",
    "            first_author_count = 0\n",
    "            if authorships:\n",
    "                first = authorships[0]\n",
    "                insts = first.get('institutions', []) or []\n",
    "                first_author_count = len(insts)\n",
    "\n",
    "            oa_info = w.get('open_access', {}) or {}\n",
    "            title_text = w.get('title') or ''\n",
    "            title_word_count = len(title_text.split()) if title_text else 0\n",
    "\n",
    "            abstract_inv = w.get('abstract_inverted_index') or {}\n",
    "            abstract_wcnt = sum(len(v) for v in abstract_inv.values()) if isinstance(abstract_inv, dict) else 0\n",
    "            concepts_cnt = len(w.get('concepts') or [])\n",
    "            related_cnt = len(w.get('related_works') or [])\n",
    "            locations_cnt = w.get('locations_count') or 0\n",
    "            oa_locations_cnt = sum(1 for loc in (w.get('locations') or []) if loc and loc.get('is_oa'))\n",
    "            has_doi = 1 if w.get('doi') else 0\n",
    "            insts_all_cnt = sum(len(a.get('institutions') or []) for a in authorships)\n",
    "\n",
    "            pub_year = w.get('publication_year') or current_year\n",
    "            years_since = max(1, (current_year - pub_year + 1))\n",
    "            citations_per_year = (w.get('cited_by_count') or 0) / years_since\n",
    "\n",
    "            row = [\n",
    "                w.get('publication_year'),\n",
    "                len(title_text),\n",
    "                title_word_count,\n",
    "                len(authorships),\n",
    "                first_author_count,\n",
    "                w.get('cited_by_count'),\n",
    "                w.get('referenced_works_count'),\n",
    "                w.get('type'),\n",
    "                w.get('language'),\n",
    "                (w['concepts'][0]['display_name'] if w.get('concepts') else None),\n",
    "                oa_info.get('is_oa'),\n",
    "                oa_info.get('oa_status'),\n",
    "                abstract_wcnt,\n",
    "                concepts_cnt,\n",
    "                related_cnt,\n",
    "                locations_cnt,\n",
    "                oa_locations_cnt,\n",
    "                has_doi,\n",
    "                insts_all_cnt,\n",
    "                citations_per_year,\n",
    "            ]\n",
    "            writer.writerow(row)\n",
    "            total_rows += 1\n",
    "            if total_rows >= 500:\n",
    "                limit_reached = True\n",
    "                break\n",
    "\n",
    "        print(f'Собрано {total_rows} статей')\n",
    "\n",
    "        if not limit_reached:\n",
    "            cursor = data['meta'].get('next_cursor')\n",
    "            if not cursor:\n",
    "                break\n",
    "            PARAMS['cursor'] = cursor\n",
    "\n",
    "        time.sleep(1.5)\n",
    "\n",
    "print(f'Выгрузка завершена. Всего статей: {total_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53c4e8",
   "metadata": {},
   "source": [
    "# Типизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c863b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON сохранён: 500 записей\n",
      "ARFF сохранён: 500 записей\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = \"data.tsv\"\n",
    "OUTPUT_JSON = \"data.json\"\n",
    "OUTPUT_ARFF = \"data.arff\"\n",
    "\n",
    "TYPE_MAP = {\n",
    "    \"Year_of_Publication\": \"integer\",\n",
    "    \"Title_Length_in_Characters\": \"integer\",\n",
    "    \"Title_Word_Count\": \"integer\",\n",
    "    \"Number_of_Authors\": \"integer\",\n",
    "    \"Number_of_Institutions_of_First_Author\": \"integer\",\n",
    "    \"Number_of_Citations\": \"integer\",\n",
    "    \"Number_of_References\": \"integer\",\n",
    "    \"Type_of_Publication\": \"category\",\n",
    "    \"Language_of_Publication\": \"category\",\n",
    "    \"Primary_Concept_of_Publication\": \"text\",\n",
    "    \"Is_Open_Access\": \"category\",\n",
    "    \"Open_Access_Type\": \"category\",\n",
    "    \"Abstract_Word_Count\": \"integer\",\n",
    "    \"Concepts_Count\": \"integer\",\n",
    "    \"Related_Works_Count\": \"integer\",\n",
    "    \"Locations_Count\": \"integer\",\n",
    "    \"OA_Locations_Count\": \"integer\",\n",
    "    \"Has_DOI\": \"integer\",\n",
    "    \"Institutions_All_Authors_Count\": \"integer\",\n",
    "    \"Citations_Per_Year\": \"numeric\",\n",
    "}\n",
    "\n",
    "data_list = []\n",
    "with open(INPUT_FILE, encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "\n",
    "    header_fields = reader.fieldnames or []\n",
    "    fields = [(name, TYPE_MAP[name]) for name in header_fields if name in TYPE_MAP]\n",
    "    unique_categories = {name: set() for name, t in fields if t == \"category\"}\n",
    "\n",
    "    for row in reader:\n",
    "        item = {}\n",
    "        for name, typ in fields:\n",
    "            raw_value = row.get(name, \"\")\n",
    "            if isinstance(raw_value, str):\n",
    "                value = raw_value.strip()\n",
    "                value = None if value == \"\" else value\n",
    "            else:\n",
    "                value = raw_value\n",
    "\n",
    "            if typ in (\"integer\", \"numeric\"):\n",
    "                try:\n",
    "                    if typ == \"integer\":\n",
    "                        item[name] = int(float(value)) if value is not None else None\n",
    "                    else:\n",
    "                        item[name] = float(value) if value is not None else None\n",
    "                except Exception:\n",
    "                    item[name] = None\n",
    "            elif typ == \"category\":\n",
    "                item[name] = value\n",
    "                if value is not None:\n",
    "                    unique_categories[name].add(str(value))\n",
    "            else:\n",
    "                item[name] = value\n",
    "        data_list.append(item)\n",
    "\n",
    "header = []\n",
    "for name, typ in fields:\n",
    "    h = {\"feature_name\": name, \"type\": typ}\n",
    "    if typ == \"category\":\n",
    "        h[\"values\"] = sorted(unique_categories.get(name, set()))\n",
    "    header.append(h)\n",
    "\n",
    "output_json = {\"header\": header, \"data\": data_list}\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_json, f, ensure_ascii=False, indent=2)\n",
    "print(f\"JSON сохранён: {len(data_list)} записей\")\n",
    "\n",
    "with open(OUTPUT_ARFF, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"@RELATION OpenAlex_Computer_Science\\n\\n\")\n",
    "    for name, typ in fields:\n",
    "        if typ == \"integer\":\n",
    "            f.write(f\"@ATTRIBUTE {name} NUMERIC\\n\")\n",
    "        elif typ == \"numeric\":\n",
    "            f.write(f\"@ATTRIBUTE {name} NUMERIC\\n\")\n",
    "        elif typ == \"text\":\n",
    "            f.write(f\"@ATTRIBUTE {name} STRING\\n\")\n",
    "        elif typ == \"category\":\n",
    "            vals = \",\".join(sorted(unique_categories.get(name, set())))\n",
    "            f.write(f\"@ATTRIBUTE {name} {{{vals}}}\\n\")\n",
    "    f.write(\"\\n@DATA\\n\")\n",
    "    for row in data_list:\n",
    "        row_str = []\n",
    "        for name, typ in fields:\n",
    "            val = row.get(name)\n",
    "            if typ == \"text\":\n",
    "                val = f'\"{val}\"' if val else \"?\"\n",
    "            elif typ in (\"integer\", \"numeric\"):\n",
    "                val = val if val is not None else \"?\"\n",
    "            elif typ == \"category\":\n",
    "                val = val if val else \"?\"\n",
    "            row_str.append(str(val))\n",
    "        f.write(\",\".join(row_str) + \"\\n\")\n",
    "print(f\"ARFF сохранён: {len(data_list)} записей\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d46bf",
   "metadata": {},
   "source": [
    "# Финальный CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ccd1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предобработка завершена. Данные сохранены в data.csv\n"
     ]
    }
   ],
   "source": [
    "INPUT_JSON = 'data.json'\n",
    "OUTPUT_CSV = 'data.csv'\n",
    "TARGET_COLUMN = 'Primary_Concept_of_Publication'\n",
    "\n",
    "with open(INPUT_JSON, encoding='utf-8') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(dataset['data'])\n",
    "\n",
    "num_cols = [h['feature_name'] for h in dataset['header'] if h['type'] in ('integer', 'numeric')]\n",
    "cat_cols = [h['feature_name'] for h in dataset['header'] if h['type'] == 'category']\n",
    "date_cols = ['Full_Publication_Date_YYYY_MM_DD']\n",
    "\n",
    "if TARGET_COLUMN in cat_cols:\n",
    "    cat_cols.remove(TARGET_COLUMN)\n",
    "\n",
    "for col in ([TARGET_COLUMN] if TARGET_COLUMN in df.columns else []) + cat_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        df[col] = df[col].replace('', pd.NA)\n",
    "\n",
    "for col in num_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "for col in list(cat_cols):\n",
    "    if df[col].isnull().all():\n",
    "        df[col] = df[col].fillna('__missing__')\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mode(dropna=True)[0])\n",
    "\n",
    "if 'Is_Open_Access' in df.columns:\n",
    "    df['Is_Open_Access'] = df['Is_Open_Access'].map({True: 1, False: 0, 'True': 1, 'False': 0, 1: 1, 0: 0})\n",
    "    if df['Is_Open_Access'].isnull().all():\n",
    "        df['Is_Open_Access'] = 0\n",
    "    else:\n",
    "        df['Is_Open_Access'] = df['Is_Open_Access'].fillna(df['Is_Open_Access'].mode(dropna=True)[0])\n",
    "    df['Is_Open_Access'] = df['Is_Open_Access'].astype(int)\n",
    "    if 'Is_Open_Access' in cat_cols:\n",
    "        cat_cols.remove('Is_Open_Access')\n",
    "\n",
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=False, dtype=int)\n",
    "\n",
    "cols_with_trailing_underscore = [c for c in df.columns if c.endswith('_')]\n",
    "if cols_with_trailing_underscore:\n",
    "    df = df.drop(columns=cols_with_trailing_underscore, errors='ignore')\n",
    "\n",
    "df = df.drop(columns=date_cols, errors='ignore')\n",
    "scaler = MinMaxScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')\n",
    "print(f'Предобработка завершена. Данные сохранены в {OUTPUT_CSV}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
